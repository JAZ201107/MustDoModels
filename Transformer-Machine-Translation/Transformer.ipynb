{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "xXg63LvrImc3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets tokenizers yacs tensorboard torchmetrics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K95oqzqyBlm1",
        "outputId": "6036eb1e-a48d-4a7a-e187-7d448f73b30b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.1.0)\n",
            "Requirement already satisfied: tokenizers in /usr/local/lib/python3.10/dist-packages (0.19.1)\n",
            "Requirement already satisfied: yacs in /usr/local/lib/python3.10/dist-packages (0.1.8)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (2.17.0)\n",
            "Requirement already satisfied: torchmetrics in /usr/local/lib/python3.10/dist-packages (1.5.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.6)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.10)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.24.7)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.64.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.7)\n",
            "Requirement already satisfied: protobuf!=4.24.0,<5.0.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.20.3)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (75.1.0)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.16.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.0.6)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (2.5.0+cu121)\n",
            "Requirement already satisfied: lightning-utilities>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (0.11.8)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.17.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.10.0->torchmetrics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard) (3.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets) (0.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "eYwRUpeuIlT5"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "from torch.utils.data import  Dataset, DataLoader, random_split\n",
        "from datasets import load_dataset\n",
        "from tokenizers import Tokenizer\n",
        "from tokenizers.models import WordLevel\n",
        "from tokenizers.trainers import WordLevelTrainer\n",
        "from tokenizers.pre_tokenizers import Whitespace\n",
        "\n",
        "\n",
        "import torchmetrics\n",
        "from tqdm import tqdm\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "\n",
        "import copy\n",
        "import math\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Configuation\n"
      ],
      "metadata": {
        "id": "OMVC-yO3bQTs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from yacs.config import CfgNode as CF\n",
        "\n",
        "__C = CF()\n",
        "\n",
        "# Training\n",
        "__C.TRAINING = CF()\n",
        "__C.TRAINING.BATCH_SIZE = 8\n",
        "__C.TRAINING.NUM_EPOCHS = 20\n",
        "__C.TRAINING.LEARNING_RATE = 1e-4\n",
        "__C.TRAINING.PRELOAD = \"latest\"\n",
        "\n",
        "\n",
        "# DATA\n",
        "__C.DATA = CF()\n",
        "__C.DATA.DATASOURCE = \"opus_books\"\n",
        "__C.DATA.LANG_SRC = \"en\"\n",
        "__C.DATA.LANG_TGT = \"it\"\n",
        "__C.DATA.TOKENIZER_FILE = \"tokenizer_{0}.json\"\n",
        "\n",
        "# MODEL\n",
        "__C.MODEL = CF()\n",
        "__C.MODEL.D_MODEL = 512\n",
        "__C.MODEL.SEQ_LEN = 350\n",
        "\n",
        "# EXPERIMENT\n",
        "__C.EXPERIMENT = CF()\n",
        "__C.EXPERIMENT.NAME = \"runs/experiences\"\n",
        "__C.EXPERIMENT.MODEL_FOLDER = \"weights\"\n",
        "# __C.EXPERIMENT.MODEL_BASENAME = \"tmodel_\"\n",
        "\n",
        "def get_config():\n",
        "    return __C.clone()\n",
        "\n",
        "\n",
        "config = get_config()"
      ],
      "metadata": {
        "id": "mMjRsh1hbRuh"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's define some helper functions"
      ],
      "metadata": {
        "id": "F_yw5xaxKWlm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def clones(layer, N):\n",
        "    return nn.ModuleList([copy.deepcopy(layer) for _ in range(N)])\n",
        "\n",
        "\n",
        "def save_checkpoint(\n",
        "        model,\n",
        "        optimizer,\n",
        "        epoch,\n",
        "        config\n",
        "):\n",
        "    checkpoint = {\n",
        "        \"model\": model.state_dict(),\n",
        "        \"optimizer\": optimizer.state_dict(),\n",
        "        \"epoch\": epoch\n",
        "    }\n",
        "\n",
        "\n",
        "    if not os.path.exists(config.EXPERIMENT.NAME):\n",
        "        print(f\"Creating directory {config.EXPERIMENT.NAME}\")\n",
        "        os.makedirs(config.EXPERIMENT.NAME)\n",
        "\n",
        "    file_path = os.path.join(config.EXPERIMENT.NAME, \"transformer.model\")\n",
        "    torch.save(checkpoint, file_path)\n",
        "\n",
        "def load_checkpoint(config):\n",
        "    file_path = os.path.join(config.EXPERIMENT.NAME,  \"transformer.model\")\n",
        "    checkpoint = torch.load(file_path)\n",
        "    return checkpoint"
      ],
      "metadata": {
        "id": "725AnIEXKZzT"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Encoder Decoder Architecture"
      ],
      "metadata": {
        "id": "JDhbq8bxIv_x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderDecoder(nn.Module):\n",
        "    def __init__(self, encoder, decoder, src_embed, tgt_embed,  generator):\n",
        "        super().__init__()\n",
        "\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.src_embed = src_embed\n",
        "        self.tgt_embed = tgt_embed\n",
        "\n",
        "        self.generator = generator\n",
        "\n",
        "    def forward(self, src, tgt, src_mask, tgt_mask):\n",
        "        memory = self.encode(src, src_mask)\n",
        "        return self.decode(memory, src_mask, tgt, tgt_mask)\n",
        "\n",
        "    def encode(self, src, src_mask):\n",
        "        return self.encoder(self.src_embed(src), src_mask)\n",
        "\n",
        "    def decode(self, memory, src_mask, tgt, tgt_mask):\n",
        "        return self.decoder(\n",
        "            self.tgt_embed(tgt),\n",
        "            memory,\n",
        "            src_mask,\n",
        "            tgt_mask\n",
        "        )"
      ],
      "metadata": {
        "id": "_8YIy02NIs1T"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self, d_model, vocab):\n",
        "        super().__init__()\n",
        "\n",
        "        self.proj = nn.Linear(d_model, vocab)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return F.log_softmax(self.proj(x), dim = -1)"
      ],
      "metadata": {
        "id": "_L97qNiFJ0aQ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SublayerConnection(nn.Module):\n",
        "    def __init__(self, size, dropout):\n",
        "        super().__init__()\n",
        "\n",
        "        self.norm = nn.LayerNorm(size)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, sublayer):\n",
        "        out = self.dropout(sublayer(self.norm(x)))\n",
        "        return x + out"
      ],
      "metadata": {
        "id": "a6yI2QS7KD47"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Encoder"
      ],
      "metadata": {
        "id": "PPvNoFUsJu8p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, layer, N = 6):\n",
        "        super().__init__()\n",
        "\n",
        "        self.layers = clones(layer, N )\n",
        "        self.norm = nn.LayerNorm(layer.size)\n",
        "\n",
        "    def forward(self, x, src_mask):\n",
        "        for layer in self.layers:\n",
        "            x = layer(x, src_mask)\n",
        "\n",
        "        return self.norm(x)"
      ],
      "metadata": {
        "id": "SSKVndVEJt9X"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderLayer(nn.Module):\n",
        "    def __init__(self, size, self_attn, feed_forward, dropout):\n",
        "        super().__init__()\n",
        "\n",
        "        self.self_attn = self_attn\n",
        "        self.feed_forward = feed_forward\n",
        "        self.sublayers = clones(SublayerConnection(size, dropout), 2)\n",
        "        self.size = size\n",
        "\n",
        "    def forward(self, x, mask):\n",
        "        x = self.sublayers[0](x, lambda x: self.self_attn(x, x, x, mask))\n",
        "\n",
        "        return self.sublayers[1](x, self.feed_forward)"
      ],
      "metadata": {
        "id": "rC8FCC-aLy9l"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Decoder"
      ],
      "metadata": {
        "id": "sP33q1BfMUui"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, layer, N = 6):\n",
        "        super().__init__()\n",
        "\n",
        "        self.layers = clones(layer, N)\n",
        "        self.norm = nn.LayerNorm(layer.size)\n",
        "\n",
        "    def forward(self, x, memory, src_mask, tgt_mask):\n",
        "        for layer in self.layers:\n",
        "            x = layer(x, memory, src_mask, tgt_mask)\n",
        "\n",
        "        return self.norm(x)"
      ],
      "metadata": {
        "id": "i6UoKq6wMUOK"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderLayer(nn.Module):\n",
        "    def __init__(self, size, src_attn, self_attn, feed_forward, dropout):\n",
        "        super().__init__()\n",
        "\n",
        "        self.size = size\n",
        "        self.self_attn = self_attn\n",
        "        self.src_attn = src_attn\n",
        "        self.feed_forward = feed_forward\n",
        "        self.sublayers = clones(SublayerConnection(size, dropout), 3)\n",
        "\n",
        "    def forward(self, x, memory, src_mask, tgt_mask):\n",
        "        x = self.sublayers[0](x, lambda x: self.self_attn(x, x, x, tgt_mask))\n",
        "        x = self.sublayers[1](x, lambda x: self.src_attn(x, memory, memory, src_mask))\n",
        "\n",
        "        return self.sublayers[2](x, self.feed_forward)"
      ],
      "metadata": {
        "id": "zz_AoQtrMt7C"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Attention Layer"
      ],
      "metadata": {
        "id": "-InVisGCPCnI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def attention(query, key, value, mask = None, dropout = None):\n",
        "    d_k = query.size(-1)\n",
        "\n",
        "    scores = torch.matmul(query, key.transpose(-2, -1)) / math.sqrt(d_k)\n",
        "    if mask is not None:\n",
        "        scores = scores.masked_fill(mask == 0, -1e9)\n",
        "    p_attn = F.softmax(scores, dim = -1)\n",
        "    if dropout is not None:\n",
        "        p_attn = dropout(p_attn)\n",
        "\n",
        "    return torch.matmul(p_attn ,value), p_attn"
      ],
      "metadata": {
        "id": "fq9q-gsRNZTq"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadedAttention(nn.Module):\n",
        "    def __init__(self, heads, d_model, dropout = 0.1):\n",
        "        super().__init__()\n",
        "\n",
        "        assert d_model % heads == 0\n",
        "\n",
        "        self.d_k = d_model // heads\n",
        "        self.heads = heads\n",
        "\n",
        "        self.linears = clones(nn.Linear(d_model, d_model), 4)\n",
        "        self.attn = None\n",
        "        self.dropout = nn.Dropout(p = dropout)\n",
        "\n",
        "    def forward(self, query, key, value, mask = None):\n",
        "        if mask is not None and mask.dim() < 4:\n",
        "            mask = mask.unsqueeze(1) # (1, Seq_Len, Seq_len) -> (1, 1, Seq_len, Seq_len)\n",
        "\n",
        "        nbatches = query.size(0)\n",
        "\n",
        "        query, key, value = [\n",
        "            lin(x).view(nbatches, -1, self.heads, self.d_k).transpose(1, 2)\n",
        "            for lin, x in zip(self.linears, (query, key, value))\n",
        "        ]\n",
        "\n",
        "        x, self.attn = attention(\n",
        "            query, key, value, mask = mask, dropout =  self.dropout\n",
        "        )\n",
        "        x = x.transpose(1, 2).contiguous().view(nbatches, -1, self.heads * self.d_k)\n",
        "\n",
        "        del query\n",
        "        del key\n",
        "        del value\n",
        "\n",
        "        return self.linears[-1](x)"
      ],
      "metadata": {
        "id": "WOFiuZ9jP0rj"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Position Wise FeedForward Layer"
      ],
      "metadata": {
        "id": "r3yrNSMiRVUQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionWiseFeedForward(nn.Module):\n",
        "    def __init__(self, d_model, d_ff, dropout = 0.1):\n",
        "        super().__init__()\n",
        "\n",
        "        self.w_1 = nn.Linear(d_model, d_ff)\n",
        "        self.w_2 = nn.Linear(d_ff, d_model)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.w_2(self.dropout(self.w_1(x).relu()))"
      ],
      "metadata": {
        "id": "ho6KYiqnQ_vZ"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Embedding Layer"
      ],
      "metadata": {
        "id": "KD2CqL7qRYYi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Embeddings(nn.Module):\n",
        "    def __init__(self, d_model, vocab_size):\n",
        "        super().__init__()\n",
        "\n",
        "\n",
        "        self.lut = nn.Embedding(vocab_size, d_model)\n",
        "        self.d_model = d_model\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.lut(x) * math.sqrt(self.d_model)"
      ],
      "metadata": {
        "id": "DFUhtKMYRUnY"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Absolution Position Embedding"
      ],
      "metadata": {
        "id": "_xPDzultRp4N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionalEncoder(nn.Module):\n",
        "    def __init__(self, d_model, dropout, max_len = 5000):\n",
        "        super().__init__()\n",
        "\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len).unsqueeze(1)\n",
        "        div_term = torch.exp(\n",
        "            torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model)\n",
        "        )\n",
        "\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # X: (B, Seq_len, d_model)\n",
        "        # Pe: (1, Seq_len, d_model)\n",
        "        x = x + self.pe[:, :x.size(1)].requires_grad_(False)\n",
        "        return self.dropout(x)"
      ],
      "metadata": {
        "id": "ZjdPag86Ro7l"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_model(\n",
        "        src_vocab,\n",
        "        tgt_vocab,\n",
        "        N = 6,\n",
        "        d_model = 512,\n",
        "        d_ff = 2048,\n",
        "        h = 8,\n",
        "        dropout = 0.1\n",
        "):\n",
        "    c = copy.deepcopy\n",
        "\n",
        "\n",
        "    attn = MultiHeadedAttention(\n",
        "        h, d_model\n",
        "    )\n",
        "    ff = PositionWiseFeedForward(d_model, d_ff)\n",
        "    position = PositionalEncoder(d_model, dropout)\n",
        "\n",
        "    model = EncoderDecoder(\n",
        "        Encoder(EncoderLayer(d_model, c(attn), c(ff), dropout), N),\n",
        "        Decoder(DecoderLayer(d_model, c(attn), c(attn), c(ff), dropout), N),\n",
        "        nn.Sequential(Embeddings(d_model, src_vocab), c(position)),\n",
        "        nn.Sequential(Embeddings(d_model, tgt_vocab), c(position)),\n",
        "        Generator(d_model, tgt_vocab),\n",
        "    )\n",
        "\n",
        "    for p in model.parameters():\n",
        "        if p.dim() > 1:\n",
        "            nn.init.xavier_normal_(p)\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "4-HyxpGKSRUP"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def causal_mask(size):\n",
        "    mask = torch.triu(torch.ones((1, size, size)), diagonal=1).type(torch.int8)\n",
        "    return mask == 0"
      ],
      "metadata": {
        "id": "Pj3eY_7TUlgO"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # test\n",
        "# model = make_model(100, 200)\n",
        "\n",
        "# src = torch.tensor([[1,2,3,4], [5,6,7,8]])\n",
        "# tgt = torch.tensor([[11,22,33,44], [55,66,77,88]])\n",
        "\n",
        "# src_mask = None\n",
        "# tgt_mask = causal_mask(4)\n",
        "\n",
        "# out = model(src, tgt, src_mask, tgt_mask)\n",
        "# pred = model.generator(out)\n",
        "# print(pred.shape)\n"
      ],
      "metadata": {
        "id": "ZwZXdFlbUNu6"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Now let build train the Transformer Model on real data"
      ],
      "metadata": {
        "id": "OE54AhN1XzyZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BilingualDataset(Dataset):\n",
        "    def __init__(\n",
        "            self,\n",
        "            ds,\n",
        "            tokenizer_src,\n",
        "            tokenizer_tgt,\n",
        "            src_lang,\n",
        "            tgt_lang,\n",
        "            seq_len\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.seq_len = seq_len\n",
        "        self.ds = ds\n",
        "        self.tokenizer_src = tokenizer_src\n",
        "        self.tokenizer_tgt = tokenizer_tgt\n",
        "        self.src_lang = src_lang\n",
        "        self.tgt_lang = tgt_lang\n",
        "\n",
        "        self.sos_token_id = torch.tensor(\n",
        "            [self.tokenizer_tgt.token_to_id(\"[SOS]\")], dtype = torch.int64\n",
        "        )\n",
        "        self.eos_token_id = torch.tensor(\n",
        "            [self.tokenizer_tgt.token_to_id(\"[EOS]\")], dtype=torch.int64\n",
        "        )\n",
        "        self.pad_token_id = torch.tensor(\n",
        "            [self.tokenizer_tgt.token_to_id(\"[PAD]\")], dtype=torch.int64\n",
        "        )\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.ds)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Get training source words and target words\n",
        "        src_target_pair = self.ds[idx]\n",
        "        src_text = src_target_pair[\"translation\"][self.src_lang]\n",
        "        tgt_text = src_target_pair[\"translation\"][self.tgt_lang]\n",
        "\n",
        "\n",
        "        # Transforms to tokens\n",
        "        enc_input_tokens = self.tokenizer_src.encode(src_text).ids\n",
        "        dec_input_tokens = self.tokenizer_tgt.encode(tgt_text).ids\n",
        "\n",
        "        # Add <SOS>, <EOS>, <PAD> to each source sentence\n",
        "        # The number of <PAD> we need to add, -2 because we have <SOS><EOS>\n",
        "        enc_num_padding_tokens = self.seq_len - len(enc_input_tokens) - 2\n",
        "        dec_num_padding_tokens = self.seq_len - len(dec_input_tokens) - 1 # -1 because only has <SOS>\n",
        "\n",
        "\n",
        "        if enc_num_padding_tokens < 0 or dec_num_padding_tokens < 0:\n",
        "            raise ValueError(\n",
        "                f\"The Sentence is too long for the model. Max length is {self.seq_len - 2} tokens.\"\n",
        "            )\n",
        "\n",
        "        encoder_input = torch.cat([\n",
        "            self.sos_token_id,\n",
        "            torch.tensor(enc_input_tokens, dtype = torch.int64),\n",
        "            self.eos_token_id,\n",
        "            torch.tensor([self.pad_token_id] * enc_num_padding_tokens, dtype = torch.int64)\n",
        "        ], dim = 0)\n",
        "\n",
        "        decoder_input = torch.cat([\n",
        "            self.sos_token_id,\n",
        "            torch.tensor(dec_input_tokens, dtype = torch.int64),\n",
        "            torch.tensor([self.pad_token_id] * dec_num_padding_tokens, dtype = torch.int64)\n",
        "        ], dim = 0)\n",
        "\n",
        "        label = torch.cat([\n",
        "            torch.tensor(dec_input_tokens, dtype=torch.int64),\n",
        "            self.eos_token_id,\n",
        "            torch.tensor([self.pad_token_id] * dec_num_padding_tokens, dtype=torch.int64),\n",
        "        ], dim = 0)\n",
        "\n",
        "\n",
        "        assert encoder_input.size(0) == self.seq_len\n",
        "        assert decoder_input.size(0) == self.seq_len\n",
        "        assert label.size(0) == self.seq_len\n",
        "\n",
        "        return {\n",
        "            \"encoder_input\": encoder_input,\n",
        "            \"decoder_input\": decoder_input,\n",
        "            \"encoder_mask\": (encoder_input != self.pad_token_id).unsqueeze(0).unsqueeze(0).int(),\n",
        "            \"decoder_mask\": (decoder_input != self.pad_token_id).unsqueeze(0).int()\n",
        "            & causal_mask(\n",
        "                decoder_input.size(0)\n",
        "            ),  # (1, seq_len) & (1, seq_len, seq_len),\n",
        "            \"label\": label,  # (seq_len)\n",
        "            \"src_text\": src_text,\n",
        "            \"tgt_text\": tgt_text,\n",
        "        }"
      ],
      "metadata": {
        "id": "lBN9IpxwYUHZ"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokenization"
      ],
      "metadata": {
        "id": "ic6s5RY9am8O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_all_senteces(ds, lang):\n",
        "    for example in ds:\n",
        "        yield example[\"translation\"][lang]"
      ],
      "metadata": {
        "id": "DiGHH9e2a5bU"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_or_build_tokenizer(config, ds, lang):\n",
        "    tokenizer_path = Path(config.DATA.TOKENIZER_FILE.format(lang))\n",
        "    if not Path.exists(tokenizer_path):\n",
        "        tokenizer = Tokenizer(WordLevel(unk_token=\"[UNK]\"))\n",
        "        tokenizer.pre_tokenizer = Whitespace()\n",
        "        trainer = WordLevelTrainer(\n",
        "            special_tokens=[f\"[UNK]\", \"[PAD]\", \"[SOS]\", \"[EOS]\"], min_frequency=2\n",
        "        )\n",
        "        tokenizer.train_from_iterator(get_all_senteces(ds, lang), trainer)\n",
        "        tokenizer.save(str(tokenizer_path))\n",
        "    else:\n",
        "        print(\"Loaded tokenizer from file\")\n",
        "        tokenizer = Tokenizer.from_file(str(tokenizer_path))\n",
        "\n",
        "    return tokenizer\n"
      ],
      "metadata": {
        "id": "upRDaPLtaloq"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Get training and validation dataloader"
      ],
      "metadata": {
        "id": "JrNUpRAPa-JM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_dataloader(config):\n",
        "    ds_raw = load_dataset(\n",
        "        f\"{config.DATA.DATASOURCE}\",\n",
        "        f\"{config.DATA.LANG_SRC}-{config.DATA.LANG_TGT}\",\n",
        "        split=\"train\",\n",
        "    )\n",
        "\n",
        "    tokenizer_src = get_or_build_tokenizer(config, ds_raw, config.DATA.LANG_SRC)\n",
        "    tokenizer_tgt = get_or_build_tokenizer(config, ds_raw, config.DATA.LANG_TGT)\n",
        "\n",
        "    # Keep 90% for training, 10% for validation\n",
        "    train_ds_size = int(0.9 * len(ds_raw))\n",
        "    val_ds_size = len(ds_raw) - train_ds_size\n",
        "    train_ds_raw, val_ds_raw = random_split(ds_raw, [train_ds_size, val_ds_size])\n",
        "\n",
        "    # Build Dataset\n",
        "    train_ds = BilingualDataset(\n",
        "        train_ds_raw,\n",
        "        tokenizer_src,\n",
        "        tokenizer_tgt,\n",
        "        config.DATA.LANG_SRC,\n",
        "        config.DATA.LANG_TGT,\n",
        "        config.MODEL.SEQ_LEN,\n",
        "    )\n",
        "    val_ds = BilingualDataset(\n",
        "        val_ds_raw,\n",
        "        tokenizer_src,\n",
        "        tokenizer_tgt,\n",
        "        config.DATA.LANG_SRC,\n",
        "        config.DATA.LANG_TGT,\n",
        "        config.MODEL.SEQ_LEN,\n",
        "    )\n",
        "\n",
        "    # Find the maximum length of each sentence in the source and target\n",
        "    max_len_src = 0\n",
        "    max_len_tgt = 0\n",
        "\n",
        "    for item in ds_raw:\n",
        "        src_ids = tokenizer_src.encode(item[\"translation\"][config.DATA.LANG_SRC]).ids\n",
        "        tgt_ids = tokenizer_tgt.encode(item[\"translation\"][config.DATA.LANG_TGT]).ids\n",
        "\n",
        "        max_len_src = max(max_len_src, len(src_ids))\n",
        "        max_len_tgt = max(max_len_tgt, len(tgt_ids))\n",
        "\n",
        "    print(f\"Max length of source sentence: {max_len_src}\")\n",
        "    print(f\"Max length of target sentence: {max_len_tgt}\")\n",
        "\n",
        "\n",
        "    train_dataloader = DataLoader(\n",
        "        train_ds, batch_size=config.TRAINING.BATCH_SIZE, shuffle=True\n",
        "    )\n",
        "    val_dataloader = DataLoader(val_ds, batch_size=1, shuffle=False)\n",
        "\n",
        "    return {\n",
        "        \"train_dataloader\": train_dataloader,\n",
        "        \"val_dataloader\": val_dataloader,\n",
        "        \"tokenizer_src\": tokenizer_src,\n",
        "        \"tokenizer_tgt\": tokenizer_tgt,\n",
        "    }\n"
      ],
      "metadata": {
        "id": "ecJdPDj2a8sc"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test Dataloader"
      ],
      "metadata": {
        "id": "lIArKJyMbkz0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define Decoding Methods"
      ],
      "metadata": {
        "id": "D58FtnKDdSfa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Greedy Decoding"
      ],
      "metadata": {
        "id": "B2rZb5NRdXwH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def greedy_decode(\n",
        "        model,\n",
        "        source,\n",
        "        source_mask,\n",
        "        tokenizer_tgt,\n",
        "        device,\n",
        "        max_len = 100,\n",
        "):\n",
        "    sos_idx = tokenizer_tgt.token_to_id(\"[SOS]\")\n",
        "    eos_idx = tokenizer_tgt.token_to_id(\"[EOS]\")\n",
        "\n",
        "    # Pre-compute the encoder output and reuse it for every step\n",
        "    memory = model.encode(source, source_mask)\n",
        "    decoder_input = torch.empty(1, 1).fill_(sos_idx).type(source).to(device)\n",
        "\n",
        "    while True:\n",
        "        if decoder_input.size(-1) == max_len:\n",
        "            break\n",
        "\n",
        "        # Build mask for target\n",
        "        decoder_mask = causal_mask(decoder_input.size(-1)).type_as(source_mask).to(device)\n",
        "\n",
        "        # Calculate output\n",
        "        out = model.decode(memory, src_mask, decoder_input, decoder_mask)\n",
        "        prob = model.generator(out)\n",
        "        _, next_word = prob.max(dim = -1)\n",
        "        decoder_input = torch.cat([\n",
        "            decoder_input,\n",
        "            torch.empty(1, 1).type_as(source).fill_(next_word.item()).to(device),\n",
        "        ], dim = 1)\n",
        "\n",
        "        if next_word == eos_idx:\n",
        "            break\n",
        "\n",
        "    return decoder_input.squeeze(0)"
      ],
      "metadata": {
        "id": "Wu6CUzHDcahZ"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def beam_search_decode(\n",
        "    model,\n",
        "    beam_size,\n",
        "    source,\n",
        "    source_mask,\n",
        "    tokenizer_tgt,\n",
        "    device,\n",
        "    max_len=100,\n",
        "):\n",
        "    sos_idx = tokenizer_tgt.token_to_id(\"[SOS]\")\n",
        "    eos_idx = tokenizer_tgt.token_to_id(\"[EOS]\")\n",
        "\n",
        "    memory = model.encode(source, source_mask)\n",
        "    decoder_initial_input = torch.empty(1, 1).fill_(sos_idx).type(source).to(device)\n",
        "\n",
        "    candidates = [(decoder_initial_input, 1)]\n",
        "\n",
        "    while True:\n",
        "        if any([cand.size(1) == max_len for cand, _ in candidates]):\n",
        "            break\n",
        "\n",
        "        new_candidates = []\n",
        "        for candidate, score in candidates:\n",
        "            if candidate[0, -1] == eos_idx:\n",
        "                continue\n",
        "\n",
        "            candidate_mask = causal_mask(candidate.size(1)).type_as(source_mask).to(device)\n",
        "\n",
        "            out = model.decode(memory, src_mask, candidate, candidate_mask)\n",
        "            prob = model.generator(out)\n",
        "\n",
        "            topk_prob, topk_idx = torch.topk(prob, beam_size, dim = 1)\n",
        "\n",
        "            for i in range(beam_size):\n",
        "                token = topk_idx[0][i].unsqueeze(0).unsqueeze(0)\n",
        "                token_prob = topk_prob[0][i].item()\n",
        "\n",
        "                # Create new candidate\n",
        "                new_candidate = torch.cat([candidate, token], dim=1)\n",
        "                new_candidates.append((new_candidate, score + token_prob))\n",
        "\n",
        "        # Sort the new candidates by score\n",
        "        new_candidates = sorted(new_candidates, key=lambda x: x[1], reverse=True)\n",
        "        # Get the top k candidates\n",
        "        candidates = new_candidates[:beam_size]\n",
        "\n",
        "        if all([cand[0][-1].item() == eos_idx for cand, _ in candidates]):\n",
        "            break\n",
        "\n",
        "    return candidates[0][0].squeeze(0)"
      ],
      "metadata": {
        "id": "Db2YGFcBepRK"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Next, let define training process"
      ],
      "metadata": {
        "id": "C-QlFl8QmH2e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader, val_dataloader, tokenizer_src, tokenizer_tgt = get_dataloader(config).values()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bc_DGZTCmfsN",
        "outputId": "91f643cd-e771-4d9f-a0b8-6770feeed2cd"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded tokenizer from file\n",
            "Loaded tokenizer from file\n",
            "Max length of source sentence: 309\n",
            "Max length of target sentence: 274\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oaeTTbK-nU4o",
        "outputId": "9f20de8c-16d4-4e07-a137-2cefd029ba79"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def valida_one_epoch(\n",
        "        model,\n",
        "        val_dataloader,\n",
        "        loss_fn,\n",
        "        device,\n",
        "        toeknizer_tgt,\n",
        "        max_len = 100,\n",
        "        writer = None,\n",
        "        global_step = 0\n",
        "):\n",
        "    model.eval()\n",
        "\n",
        "    count = 0\n",
        "    source_texts = []\n",
        "    expected = []\n",
        "    predicted = []\n",
        "\n",
        "    for batch in val_dataloader:\n",
        "        count += 1\n",
        "\n",
        "        encoder_input = batch[\"encoder_input\"].to(device) # (b, seq_len)\n",
        "        encoder_mask = batch[\"encoder_mask\"].to(device) # (b, 1, 1, seq_len)\n",
        "\n",
        "        assert encoder_input.size(0) == 1, \"Batch size must be 1 for validation\"\n",
        "\n",
        "        model_out = greedy_decode(\n",
        "            model,\n",
        "            encoder_input,\n",
        "            encoder_mask,\n",
        "            toeknizer_tgt,\n",
        "            device,\n",
        "            max_len,\n",
        "        )\n",
        "\n",
        "        source_text = batch[\"src_text\"][0]\n",
        "        target_text = batch[\"tgt_text\"][0]\n",
        "        model_out_text = toeknizer_tgt.decode(model_out.detach().cpu().numpy())\n",
        "\n",
        "        source_texts.append(source_text)\n",
        "        expected.append(target_text)\n",
        "        predicted.append(model_out_text)\n",
        "\n",
        "        print(f\"{f'SOURCE: ':>12}{source_text}\")\n",
        "        print(f\"{f'TARGET: ':>12}{target_text}\")\n",
        "        print(f\"{f'PREDICTED: ':>12}{model_out_text}\")\n",
        "\n",
        "    if writer is not None:\n",
        "        metric = torchmetrics.CharErrorRate()\n",
        "        cer = metric(predicted, expected)\n",
        "        writer.add_scalar('validation cer', cer, global_step)\n",
        "        writer.flush()\n",
        "\n",
        "        # Compute the word error rate\n",
        "        metric = torchmetrics.WordErrorRate()\n",
        "        wer = metric(predicted, expected)\n",
        "        writer.add_scalar('validation wer', wer, global_step)\n",
        "        writer.flush()\n",
        "\n",
        "        # Compute the BLEU metric\n",
        "        metric = torchmetrics.BLEUScore()\n",
        "        bleu = metric(predicted, expected)\n",
        "        writer.add_scalar('validation BLEU', bleu, global_step)\n",
        "        writer.flush()"
      ],
      "metadata": {
        "id": "iRabEASgnT0n"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_one_epoch(\n",
        "        model,\n",
        "        train_dataloader,\n",
        "        optimizer,\n",
        "        loss_fn,\n",
        "        cur_epoch,\n",
        "        tokenizer_tgt,\n",
        "):\n",
        "    model.train()\n",
        "\n",
        "    batch_iterator = tqdm(train_dataloader, desc=f\"Processing Epoch {cur_epoch:02d}\")\n",
        "    steps = 0\n",
        "    for batch in batch_iterator:\n",
        "        encoder_input = batch['encoder_input'].to(device) # (b, seq_len)\n",
        "        decoder_input = batch['decoder_input'].to(device) # (B, seq_len)\n",
        "        encoder_mask = batch['encoder_mask'].to(device) # (B, 1, 1, seq_len)\n",
        "        decoder_mask = batch['decoder_mask'].to(device) # (B, 1, seq_len, seq_len)\n",
        "\n",
        "        # Run the tensors through the encoder, decoder and the projection layer\n",
        "        encoder_output = model.encode(encoder_input, encoder_mask) # (B, seq_len, d_model)\n",
        "        decoder_output = model.decode(encoder_output, encoder_mask, decoder_input, decoder_mask) # (B, seq_len, d_model)\n",
        "        proj_output = model.generator(decoder_output) # (B, seq_len, vocab_size)\n",
        "\n",
        "        # Compare the output with the label\n",
        "        label = batch['label'].to(device) # (B, seq_len)\n",
        "\n",
        "        loss = loss_fn(proj_output.view(-1, tokenizer_tgt.get_vocab_size()), label.view(-1))\n",
        "        batch_iterator.set_postfix({\"loss\": f\"{loss.item():6.3f}\"})\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        steps += 1\n",
        "\n",
        "    return steps"
      ],
      "metadata": {
        "id": "_h6iKuqgpANg"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(\n",
        "    model,\n",
        "    loss_fn,\n",
        "    optimizer,\n",
        "    train_dataloader,\n",
        "    val_dataloader,\n",
        "    config\n",
        "):\n",
        "    writer = SummaryWriter(config.EXPERIMENT.NAME)\n",
        "    global_step = 0\n",
        "    for epoch in range(config.TRAINING.NUM_EPOCHS):\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "        global_step += train_one_epoch(\n",
        "            model,\n",
        "            train_dataloader,\n",
        "            optimizer,\n",
        "            loss_fn,\n",
        "            epoch,\n",
        "            tokenizer_tgt\n",
        "        )\n",
        "\n",
        "        valida_one_epoch(\n",
        "            model,\n",
        "            val_dataloader,\n",
        "            loss_fn,\n",
        "            device,\n",
        "            tokenizer_tgt,\n",
        "            writer = writer,\n",
        "            global_step = global_step\n",
        "        )\n",
        "\n",
        "\n",
        "        if epoch % 5 == 0:\n",
        "            save_checkpoint(\n",
        "                model,\n",
        "                optimizer,\n",
        "                epoch,\n",
        "                config\n",
        "            )"
      ],
      "metadata": {
        "id": "mcky_Z8zpyCQ"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = make_model(\n",
        "    tokenizer_src.get_vocab_size(),\n",
        "    tokenizer_tgt.get_vocab_size(),\n",
        ").to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = config.TRAINING.LEARNING_RATE, eps=1e-9)\n",
        "loss_fn = nn.CrossEntropyLoss(\n",
        "    ignore_index=tokenizer_src.token_to_id(\"[PAD]\"),\n",
        "    label_smoothing=0.1\n",
        ").to(device)\n",
        "\n",
        "train_model(\n",
        "    model,\n",
        "    loss_fn ,\n",
        "    optimizer,\n",
        "    train_dataloader,\n",
        "    val_dataloader,\n",
        "    config\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9fSZcpvbqhTH",
        "outputId": "fda1ac23-7ebd-48a1-89a8-9f23cf684697"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch 00:   0%|          | 3/3638 [01:27<29:14:55, 28.97s/it, loss=9.747]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Let do some testing!!"
      ],
      "metadata": {
        "id": "e20i6wThqjOZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Ensure TensorBoard extension is loaded\n",
        "# %load_ext tensorboard\n",
        "# # Start TensorBoard and point it to the log directory\n",
        "# %tensorboard --logdir=runs"
      ],
      "metadata": {
        "id": "EzQNRgaZrHdN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "n-eUVRbhrK0T"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}